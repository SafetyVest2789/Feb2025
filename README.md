# Feb2025
Ollama "no remote code" local host only "zero drama" AI RAG. Using llama3.2 and upgrading to a chonky boi llama3.3 in March 2025. Project will consist of turning PDF into JSON format and querying with a locally hosted RAG LLM model.

Grab a ollama model. Here's the documentation to help you get started with cURL testing. 

https://github.com/ollama/ollama/blob/main/docs/api.md#show-model-information